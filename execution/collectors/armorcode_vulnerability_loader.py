#!/usr/bin/env python3
"""
ArmorCode Vulnerability Detail Loader

Fetches individual vulnerability details from ArmorCode GraphQL API.
Extends armorcode_loader.py with detailed vulnerability queries.

Usage:
    from execution.collectors.armorcode_vulnerability_loader import ArmorCodeVulnerabilityLoader

    loader = ArmorCodeVulnerabilityLoader()
    vulnerabilities = loader.load_vulnerabilities_for_products(['Product1', 'Product2'])
"""

import os
import time
from dataclasses import dataclass
from datetime import datetime

from dotenv import load_dotenv

from execution.http_client import post
from execution.secure_config import get_config
from execution.utils.datetime_utils import parse_ado_timestamp

load_dotenv()


@dataclass
class VulnerabilityDetail:
    """Individual vulnerability details from ArmorCode"""

    id: str
    title: str
    description: str
    severity: str  # CRITICAL, HIGH, MEDIUM, LOW
    status: str  # OPEN, CONFIRMED, etc.
    created_at: str
    product: str
    age_days: int
    environment: str | None = None  # Production, Staging, Development, etc.
    source: str | None = None  # Source tool (Mend, SonarQube, Cortex XDR, etc.)

    @property
    def is_critical(self) -> bool:
        """Check if vulnerability is critical"""
        return self.severity == "CRITICAL"

    @property
    def is_high(self) -> bool:
        """Check if vulnerability is high severity"""
        return self.severity == "HIGH"

    @property
    def is_critical_or_high(self) -> bool:
        """Check if vulnerability is critical or high"""
        return self.severity in ["CRITICAL", "HIGH"]

    @property
    def is_production(self) -> bool:
        """Check if vulnerability is in production environment"""
        return bool(self.environment and self.environment.upper() == "PRODUCTION")


class ArmorCodeVulnerabilityLoader:
    """
    Loads detailed vulnerability information from ArmorCode GraphQL API.
    """

    api_key: str | None
    base_url: str | None
    graphql_url: str | None

    def __init__(self):
        """Initialize with ArmorCode config"""
        config = get_config()
        try:
            armorcode_config = config.get_armorcode_config()
            self.api_key = armorcode_config.api_key
            self.base_url = armorcode_config.base_url
        except Exception as e:
            print(f"[WARNING] ArmorCode config not available: {e}")
            self.api_key = None
            self.base_url = None

        self.graphql_url = f"{self.base_url.rstrip('/')}/api/graphql" if self.base_url else None

    def get_product_ids(self, product_names: list[str]) -> dict[str, str]:
        """
        Get product IDs for specified product names via GraphQL.

        Args:
            product_names: List of product names to look up

        Returns:
            Dictionary mapping product names to IDs
        """
        if not self.api_key or not self.graphql_url:
            print("[WARNING] ArmorCode API not configured")
            return {}

        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}

        all_products = []

        # Fetch all pages of products
        for page in range(1, 10):  # Max 10 pages
            query = f"""
            {{
              products(page: {page}, size: 100) {{
                products {{
                  id
                  name
                }}
                pageInfo {{
                  hasNext
                }}
              }}
            }}
            """

            try:
                response = post(self.graphql_url or "", headers=headers, json={"query": query}, timeout=60)
                if response.status_code == 200:
                    data = response.json()
                    if "data" in data and "products" in data["data"]:
                        result = data["data"]["products"]
                        products = result.get("products", [])
                        all_products.extend(products)

                        if not result.get("pageInfo", {}).get("hasNext", False):
                            break
            except Exception as e:
                print(f"[WARNING] Error fetching products page {page}: {e}")
                break

        # Map product names to IDs
        product_map = {p["name"]: p["id"] for p in all_products}
        print(f"[INFO] Mapped {len(product_map)} products to IDs")

        return product_map

    def load_vulnerabilities_for_products(
        self, product_names: list[str], filter_environment: bool = True
    ) -> list[VulnerabilityDetail]:
        """
        Load all vulnerability details for specified products (no page cap).
        Use load_vulnerabilities_hybrid() for capped fetch + accurate bucket counts.
        """
        if not self.api_key or not self.graphql_url:
            print("[WARNING] ArmorCode API not configured - cannot fetch vulnerability details")
            return []

        # Get product IDs first
        print(f"[INFO] Fetching product IDs for {len(product_names)} products...")
        product_id_map = self.get_product_ids(product_names)

        if not product_id_map:
            print("[WARNING] No product IDs found")
            return []

        all_vulnerabilities: list[VulnerabilityDetail] = []

        for product_name in product_names:
            if product_name not in product_id_map:
                print(f"[WARNING] Product not found in ArmorCode: {product_name}")
                continue
            product_id = product_id_map[product_name]
            print(f"[INFO] Querying findings for: {product_name}")
            time.sleep(1)
            fetched, _ = self._fetch_product_pages(product_id, product_name, max_pages=100)
            all_vulnerabilities.extend(fetched)

        print(f"[SUCCESS] Retrieved {len(all_vulnerabilities)} vulnerability details")
        if filter_environment:
            all_vulnerabilities = self.filter_by_environment(all_vulnerabilities)
        return all_vulnerabilities

    def _count_findings(self, product_id: str, source: str, severity: str, headers: dict) -> int:
        """Return totalElements from a minimal count query (page=1, size=1). Returns 0 on error."""
        query = f"""{{
          findings(page: 1 size: 1
            findingFilter: {{
              product: [{product_id}]
              severity: [{severity}]
              status: ["OPEN", "CONFIRMED"]
              source: "{source}"
            }}
          ) {{ findings {{ id }} pageInfo {{ totalElements }} }}
        }}"""
        try:
            r = post(self.graphql_url or "", headers=headers, json={"query": query}, timeout=30)
            if r.status_code == 200:
                data = r.json()
                if "data" in data and "findings" in data["data"]:
                    return int(data["data"]["findings"]["pageInfo"]["totalElements"])
        except Exception:
            pass
        return 0

    def _count_product_severity(self, product_id: str, severity: str) -> int:
        """Return accurate totalElements for a product/severity with no source filter.

        Used for grand-total counts only. Independent of the detail-fetch cap.
        """
        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        query = f"""{{
          findings(page: 1 size: 1
            findingFilter: {{
              product: [{product_id}]
              severity: [{severity}]
              status: ["OPEN", "CONFIRMED"]
            }}
          ) {{ findings {{ id }} pageInfo {{ totalElements }} }}
        }}"""
        try:
            r = post(self.graphql_url or "", headers=headers, json={"query": query}, timeout=30)
            if r.status_code == 200:
                data = r.json()
                if "data" in data and "findings" in data["data"]:
                    return int(data["data"]["findings"]["pageInfo"]["totalElements"])
        except Exception:
            pass
        return 0

    def _fetch_source_counts(self, product_id: str, product_name: str) -> dict[str, dict]:
        """
        Get accurate per-bucket counts via source-filtered totalElements queries.
        Called only when a product has >500 total findings.
        Returns {bucket_name: {"total": int, "critical": int, "high": int}}.
        """
        from execution.domain.security import SOURCE_BUCKET_MAP

        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        bucket_counts: dict[str, dict] = {}
        for source in SOURCE_BUCKET_MAP:
            crit = self._count_findings(product_id, source, "Critical", headers)
            high = self._count_findings(product_id, source, "High", headers)
            if crit + high == 0:
                continue
            bucket = SOURCE_BUCKET_MAP[source]
            if bucket not in bucket_counts:
                bucket_counts[bucket] = {"total": 0, "critical": 0, "high": 0}
            bucket_counts[bucket]["critical"] += crit
            bucket_counts[bucket]["high"] += high
            bucket_counts[bucket]["total"] += crit + high
        print(f"  [COUNTS] {product_name}: {bucket_counts}")
        return bucket_counts

    def _fetch_product_pages(
        self, product_id: str, product_name: str, max_pages: int, source: str | None = None
    ) -> tuple[list[VulnerabilityDetail], int]:
        """
        Fetch up to max_pages of findings for one product.
        Returns (vulnerabilities, total_elements_from_page1).
        """
        vulns: list[VulnerabilityDetail] = []
        total_elements = 0
        page = 1
        has_next = True
        retry_count = 0
        max_retries = 3

        while has_next and page <= max_pages:
            src_filter = f'\n                  source: "{source}"' if source else ""
            query = f"""
            {{
              findings(
                page: {page}
                size: 100
                findingFilter: {{
                  product: [{product_id}]
                  status: ["OPEN", "CONFIRMED"]
                  severity: [Critical, High]{src_filter}
                }}
              ) {{
                findings {{
                  id title description severity status source createdAt
                  environment {{ name id }}
                }}
                pageInfo {{ hasNext totalElements }}
              }}
            }}
            """
            try:
                response = post(
                    self.graphql_url or "",
                    headers={"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"},
                    json={"query": query},
                    timeout=60,
                )
                if response.status_code == 200:
                    data = response.json()
                    if "errors" in data:
                        print(f"  [ERROR] GraphQL error: {data['errors']}")
                        break
                    if "data" in data and "findings" in data["data"]:
                        result = data["data"]["findings"]
                        findings = result.get("findings", [])
                        page_info = result.get("pageInfo", {})
                        if page == 1:
                            total_elements = page_info.get("totalElements", 0)
                        for finding in findings:
                            created_at = finding.get("createdAt", "")
                            environment = None
                            if finding.get("environment"):
                                environment = finding["environment"].get("name")
                            vulns.append(
                                VulnerabilityDetail(
                                    id=finding.get("id", ""),
                                    title=finding.get("title", ""),
                                    description=finding.get("description", ""),
                                    severity=finding.get("severity", ""),
                                    status=finding.get("status", ""),
                                    created_at=created_at,
                                    product=product_name,
                                    age_days=self._calculate_age_days(created_at),
                                    environment=environment,
                                    source=finding.get("source"),
                                )
                            )
                        print(f"  Found {len(findings)} vulnerabilities (page {page})")
                        has_next = page_info.get("hasNext", False)
                        page += 1
                    else:
                        break
                elif response.status_code == 429:
                    retry_after = int(response.headers.get("Retry-After", 60))
                    retry_count += 1
                    if retry_count <= max_retries:
                        print(f"  [RATE LIMIT] HTTP 429 - waiting {retry_after}s ({retry_count}/{max_retries})...")
                        time.sleep(retry_after)
                    else:
                        print(f"  [ERROR] HTTP 429 - max retries exceeded for {product_name}")
                        break
                else:
                    print(f"  [ERROR] HTTP {response.status_code}")
                    break
            except Exception as e:
                print(f"  [ERROR] Query failed: {e}")
                break

        return vulns, total_elements

    def load_vulnerabilities_hybrid(
        self,
        product_names: list[str],
        filter_environment: bool = True,
        max_per_product: int = 50,
    ) -> tuple[list[VulnerabilityDetail], dict[str, dict | None], dict[str, dict]]:
        """
        Hybrid load: capped detail fetch + accurate counts via dedicated count queries.

        Returns (vulnerabilities, bucket_counts_by_product, accurate_totals) where:
        - vulnerabilities: detail records capped at max_per_product per product (for expandable rows)
        - bucket_counts_by_product[name] = dict  {bucket: {total, critical, high}} for large products
        - bucket_counts_by_product[name] = None  for small products (derive display from fetched)
        - accurate_totals[name] = {critical, high, total} from dedicated no-source-filter count queries

        Args:
            product_names: List of product names to query
            filter_environment: Filter by ARMORCODE_ENVIRONMENT config setting
            max_per_product: Max detail records to fetch per product (for expandable rows, default 50)
        """
        if not self.api_key or not self.graphql_url:
            print("[WARNING] ArmorCode API not configured")
            return [], {}, {}

        print(f"[INFO] Fetching product IDs for {len(product_names)} products...")
        product_id_map = self.get_product_ids(product_names)
        max_pages = max(1, max_per_product // 100)

        all_vulns: list[VulnerabilityDetail] = []
        bucket_counts_by_product: dict[str, dict | None] = {}
        accurate_totals: dict[str, dict] = {}

        for product_name in product_names:
            if product_name not in product_id_map:
                print(f"[WARNING] Product not found in ArmorCode: {product_name}")
                bucket_counts_by_product[product_name] = None
                accurate_totals[product_name] = {"critical": 0, "high": 0, "total": 0}
                continue

            product_id = product_id_map[product_name]
            print(f"[INFO] Querying findings for: {product_name}")
            time.sleep(1)

            fetched, total_elements = self._fetch_product_pages(product_id, product_name, max_pages)
            if filter_environment:
                fetched = self.filter_by_environment(fetched)
            # Cap detail records — only used for expandable table rows, not for counts
            if len(fetched) > max_per_product:
                fetched = fetched[:max_per_product]
            all_vulns.extend(fetched)

            if total_elements > max_per_product:
                bkt_c = self._fetch_source_counts(product_id, product_name)
                bucket_counts_by_product[product_name] = bkt_c
                # Targeted fetch for small buckets absent from the capped main fetch
                from execution.domain.security import SOURCE_BUCKET_MAP as _SBM

                fetched_bkts = {_SBM.get(v.source or "", "Other") for v in fetched}
                missing = {b for b, c in bkt_c.items() if c["total"] <= max_per_product and b not in fetched_bkts}
                for src, bkt in _SBM.items():
                    if bkt in missing:
                        extra, _ = self._fetch_product_pages(product_id, product_name, max_pages, source=src)
                        if filter_environment:
                            extra = self.filter_by_environment(extra)
                        all_vulns.extend(extra)
            else:
                bucket_counts_by_product[product_name] = None

            # Always get accurate totals via dedicated count queries (no source filter)
            crit = self._count_product_severity(product_id, "Critical")
            high = self._count_product_severity(product_id, "High")
            accurate_totals[product_name] = {"critical": crit, "high": high, "total": crit + high}

        print(f"[SUCCESS] Retrieved {len(all_vulns)} vulnerability details (capped at {max_per_product}/product)")
        return all_vulns, bucket_counts_by_product, accurate_totals

    def _calculate_age_days(self, created_at: str) -> int:
        """Calculate age in days from created_at timestamp"""
        if not created_at:
            return 0

        try:
            # Parse ArmorCode format: "Wed Dec 24 16:07:49 UTC 2025"
            created_date = datetime.strptime(created_at, "%a %b %d %H:%M:%S UTC %Y")
            age = datetime.now() - created_date
            return age.days
        except ValueError:
            # Try ISO format fallback (e.g., "2024-01-15T10:30:00Z")
            try:
                created_date_parsed = parse_ado_timestamp(created_at)
                if created_date_parsed:
                    age = datetime.now() - created_date_parsed.replace(tzinfo=None)
                    return age.days
                return 0
            except Exception as e:
                print(f"[WARN] Failed to parse date '{created_at}': {e}")
                return 0

    def filter_by_environment(
        self, vulnerabilities: list[VulnerabilityDetail], environment: str | None = None
    ) -> list[VulnerabilityDetail]:
        """
        Filter vulnerabilities by environment.

        Args:
            vulnerabilities: List of VulnerabilityDetail objects
            environment: Environment name to filter by (e.g., "Production", "Staging").
                        If None, uses ARMORCODE_ENVIRONMENT from config.
                        Case-insensitive comparison.

        Returns:
            Filtered list of VulnerabilityDetail objects

        Example:
            loader = ArmorCodeVulnerabilityLoader()
            all_vulns = loader.load_vulnerabilities_for_products(['Product1'])
            prod_vulns = loader.filter_by_environment(all_vulns, "Production")
        """
        # Get environment filter from parameter or config
        if environment is None:
            try:
                config = get_config()
                environment = config.get_optional_env("ARMORCODE_ENVIRONMENT")
            except Exception:
                environment = None

        # If no environment specified, return all
        if not environment:
            print("[INFO] No environment filter specified - returning all vulnerabilities")
            return vulnerabilities

        # Filter by environment (case-insensitive)
        environment_upper = environment.upper()
        filtered = [v for v in vulnerabilities if v.environment and v.environment.upper() == environment_upper]

        print(
            f"[INFO] Filtered {len(vulnerabilities)} vulnerabilities to {len(filtered)} "
            f"for environment: {environment}"
        )

        return filtered

    def count_by_severity_aql(
        self,
        severity: str,
        hierarchy: str,
        environment: str = "Production",
    ) -> dict[str, int]:
        """
        Count findings by product using the AQL count endpoint.

        Single API call per severity — no pagination, no per-product iteration.
        Returns exact counts grouped by product ID.

        Args:
            severity: "Critical" or "High"
            hierarchy: ArmorCode hierarchy value (from ARMORCODE_HIERARCHY env var)
            environment: Environment filter (default "Production")

        Returns:
            Dict mapping product_id_str -> count (0 for products with no findings)
        """
        if not self.api_key or not self.base_url:
            print("[WARNING] ArmorCode API not configured")
            return {}

        count_url = f"{self.base_url.rstrip('/')}/user/findings/groups/count"
        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        aql = (
            f"severity = {severity}"
            f" AND status IN (Open,Confirm)"
            f" AND environment = {environment}"
            f" AND hierarchy = 'armorcode.group:{hierarchy}'"
        )
        payload = {
            "aggField": "product",
            "filters": {"aqlQuery": [aql]},
            "ignoreDuplicate": True,
            "ignoreMitigated": None,
        }

        try:
            resp = post(count_url, headers=headers, json=payload, timeout=30)
            if resp.status_code == 200:
                data = resp.json()
                return {k: v.get("count", 0) for k, v in data.items() if isinstance(v, dict)}
            print(f"[ERROR] AQL count HTTP {resp.status_code}: {resp.text[:200]}")
        except Exception as e:
            print(f"[ERROR] AQL count query failed for severity={severity}: {e}")
        return {}

    def group_by_product(self, vulnerabilities: list[VulnerabilityDetail]) -> dict[str, list[VulnerabilityDetail]]:
        """
        Group vulnerabilities by product name.

        Args:
            vulnerabilities: List of VulnerabilityDetail objects

        Returns:
            Dictionary mapping product names to vulnerability lists
        """
        grouped: dict[str, list[VulnerabilityDetail]] = {}

        for vuln in vulnerabilities:
            if vuln.product not in grouped:
                grouped[vuln.product] = []
            grouped[vuln.product].append(vuln)

        return grouped


# Self-test
if __name__ == "__main__":
    print("ArmorCode Vulnerability Loader - Self Test")
    print("=" * 60)

    loader = ArmorCodeVulnerabilityLoader()

    if not loader.api_key:
        print("[ERROR] ARMORCODE_API_KEY not configured")
        print("Set in .env file:")
        print("  ARMORCODE_API_KEY=your-uuid-key")
        print("  ARMORCODE_BASE_URL=https://app.armorcode.com")
    else:
        print("[OK] ArmorCode API configured")
        print(f"  Base URL: {loader.base_url}")
        print(f"  GraphQL URL: {loader.graphql_url}")

        # Test product ID lookup
        test_products = ["TestProduct"]  # Replace with real product name
        print(f"\nTesting product ID lookup for: {test_products}")
        product_ids = loader.get_product_ids(test_products)
        print(f"  Found {len(product_ids)} product IDs")

        # Test vulnerability loading (if you want to test with real data)
        # vulns = loader.load_vulnerabilities_for_products(test_products)
        # print(f"\nFound {len(vulns)} vulnerabilities")
        # for vuln in vulns[:5]:
        #     print(f"  - {vuln.severity}: {vuln.title[:50]}... ({vuln.age_days} days)")
