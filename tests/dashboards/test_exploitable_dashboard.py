"""
Tests for Exploitable Vulnerabilities Dashboard Generator

Tests cover:
- Domain model: ExploitableMetrics properties and from_json()
- Stage 1: Data loading from exploitable_history.json (mocked)
- Stage 2: Summary calculation (totals, status determination)
- Stage 3: Product row generation, summary cards, context building
- Stage 3: _generate_bucket_expanded_content() — bucket hierarchy + vuln table
- Stage 4: End-to-end dashboard generation with mocked file I/O
- Edge cases: empty data, all-zero counts, 10k limit flag, XSS prevention, top-50 truncation
"""

import json
from datetime import datetime
from pathlib import Path
from unittest.mock import patch

import pytest

from execution.dashboards.exploitable_dashboard import (
    _build_context,
    _build_product_rows,
    _build_summary_cards,
    _calculate_summary,
    _generate_bucket_expanded_content,
    _load_data,
    _load_latest_findings,
    generate_exploitable_dashboard,
)
from execution.domain.exploitable import ExploitableMetrics

# ---------------------------------------------------------------------------
# Fixtures
# ---------------------------------------------------------------------------


@pytest.fixture
def sample_timestamp() -> datetime:
    return datetime(2026, 2, 19, 10, 0, 0)


@pytest.fixture
def sample_metrics(sample_timestamp) -> list[ExploitableMetrics]:
    """Three products with varying exploitable counts (one incomplete)."""
    return [
        ExploitableMetrics(
            timestamp=sample_timestamp,
            project="Eclipse",
            product="Eclipse",
            critical=11,
            high=4,
            high_data_complete=False,
            bucket_breakdown={"INFRASTRUCTURE": {"critical": 11, "high": 4}},
            top_cves=["CVE-2025-59287", "CVE-2025-24813", "CVE-2022-34721"],
        ),
        ExploitableMetrics(
            timestamp=sample_timestamp,
            project="Portal",
            product="Portal",
            critical=0,
            high=3,
            high_data_complete=True,
            bucket_breakdown={"CODE": {"critical": 0, "high": 3}},
            top_cves=["CVE-2024-12345"],
        ),
        ExploitableMetrics(
            timestamp=sample_timestamp,
            project="CleanProduct",
            product="CleanProduct",
            critical=0,
            high=0,
            high_data_complete=True,
            bucket_breakdown={},
            top_cves=[],
        ),
    ]


@pytest.fixture
def sample_findings() -> list[dict]:
    """Individual finding dicts matching exploitable_latest.json format."""
    return [
        {
            "id": "f1",
            "title": "PrintNightmare",
            "severity": "Critical",
            "source": "Tenable VM",
            "status": "OPEN",
            "age_days": 312,
            "cve": "CVE-2021-34527",
            "bucket": "INFRASTRUCTURE",
        },
        {
            "id": "f2",
            "title": "Log4Shell",
            "severity": "High",
            "source": "Tenable VM",
            "status": "OPEN",
            "age_days": 150,
            "cve": "CVE-2021-44228",
            "bucket": "INFRASTRUCTURE",
        },
    ]


@pytest.fixture
def sample_history_json() -> dict:
    """History JSON matching the collector output format."""
    return {
        "weeks": [
            {
                "week_date": "2026-02-19",
                "week_number": 8,
                "metrics": {
                    "current_total": 18,
                    "severity_breakdown": {"critical": 11, "high": 7, "total": 18},
                    "high_data_complete": False,
                    "collected_at": "2026-02-19T10:00:00",
                    "product_breakdown": {
                        "Eclipse": {
                            "critical": 11,
                            "high": 4,
                            "high_data_complete": False,
                            "total": 15,
                            "buckets": {"INFRASTRUCTURE": {"critical": 11, "high": 4}},
                            "top_cves": ["CVE-2025-59287", "CVE-2025-24813"],
                        },
                        "Portal": {
                            "critical": 0,
                            "high": 3,
                            "high_data_complete": True,
                            "total": 3,
                            "buckets": {"CODE": {"critical": 0, "high": 3}},
                            "top_cves": ["CVE-2024-12345"],
                        },
                    },
                },
            }
        ]
    }


# ---------------------------------------------------------------------------
# Domain Model Tests
# ---------------------------------------------------------------------------


class TestExploitableMetrics:
    """Test ExploitableMetrics domain model properties and factory method."""

    def test_total_is_critical_plus_high(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=5, high=3)
        assert m.total == 8

    def test_total_zero(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=0, high=0)
        assert m.total == 0

    def test_status_action_needed_when_critical(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=1, high=0)
        assert m.status == "Action Needed"
        assert m.status_class == "action"

    def test_status_caution_when_only_high(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=0, high=5)
        assert m.status == "Caution"
        assert m.status_class == "caution"

    def test_status_good_when_zero(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=0, high=0)
        assert m.status == "Good"
        assert m.status_class == "good"

    def test_status_action_overrides_high(self, sample_timestamp):
        """Critical trumps High — status is Action Needed even if high > 0."""
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=3, high=10)
        assert m.status == "Action Needed"
        assert m.status_class == "action"

    def test_primary_bucket_returns_highest_total(self, sample_timestamp):
        m = ExploitableMetrics(
            timestamp=sample_timestamp,
            project="P",
            product="P",
            critical=0,
            high=0,
            bucket_breakdown={
                "CODE": {"critical": 0, "high": 2},
                "INFRASTRUCTURE": {"critical": 5, "high": 1},
            },
        )
        assert m.primary_bucket == "INFRASTRUCTURE"

    def test_primary_bucket_code_when_most(self, sample_timestamp):
        m = ExploitableMetrics(
            timestamp=sample_timestamp,
            project="P",
            product="P",
            critical=0,
            high=0,
            bucket_breakdown={
                "CODE": {"critical": 0, "high": 10},
                "INFRASTRUCTURE": {"critical": 1, "high": 0},
            },
        )
        assert m.primary_bucket == "CODE"

    def test_primary_bucket_other_when_empty(self, sample_timestamp):
        m = ExploitableMetrics(
            timestamp=sample_timestamp,
            project="P",
            product="P",
            critical=0,
            high=0,
            bucket_breakdown={},
        )
        assert m.primary_bucket == "Other"

    def test_from_json_populates_all_fields(self, sample_timestamp):
        data = {
            "critical": 11,
            "high": 4,
            "high_data_complete": False,
            "buckets": {"INFRASTRUCTURE": {"critical": 11, "high": 4}},
            "top_cves": ["CVE-2025-59287"],
        }
        m = ExploitableMetrics.from_json("Eclipse", data, sample_timestamp)
        assert m.product == "Eclipse"
        assert m.critical == 11
        assert m.high == 4
        assert m.high_data_complete is False
        assert m.bucket_breakdown == {"INFRASTRUCTURE": {"critical": 11, "high": 4}}
        assert m.top_cves == ["CVE-2025-59287"]
        assert m.timestamp == sample_timestamp

    def test_from_json_defaults_for_missing_fields(self, sample_timestamp):
        data = {"critical": 2, "high": 0}
        m = ExploitableMetrics.from_json("Minimal", data, sample_timestamp)
        assert m.critical == 2
        assert m.high == 0
        assert m.high_data_complete is True
        assert m.bucket_breakdown == {}
        assert m.top_cves == []

    def test_from_json_sets_project_and_product(self, sample_timestamp):
        m = ExploitableMetrics.from_json("TestProd", {}, sample_timestamp)
        assert m.project == "TestProd"
        assert m.product == "TestProd"


# ---------------------------------------------------------------------------
# Stage 1: Load Data Tests
# ---------------------------------------------------------------------------


class TestLoadData:
    """Test _load_data() — Stage 1."""

    def test_returns_empty_when_no_history_file(self):
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = False
            result = _load_data()
        assert result == []

    def test_returns_empty_when_no_weeks(self):
        empty = json.dumps({"weeks": []})
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = empty
            result = _load_data()
        assert result == []

    def test_loads_products_from_latest_week(self, sample_history_json):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result = _load_data()
        assert len(result) == 2
        names = {m.product for m in result}
        assert "Eclipse" in names
        assert "Portal" in names

    def test_loads_correct_counts(self, sample_history_json):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result = _load_data()
        eclipse = next(m for m in result if m.product == "Eclipse")
        assert eclipse.critical == 11
        assert eclipse.high == 4
        assert eclipse.high_data_complete is False

    def test_loads_bucket_breakdown(self, sample_history_json):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result = _load_data()
        eclipse = next(m for m in result if m.product == "Eclipse")
        assert "INFRASTRUCTURE" in eclipse.bucket_breakdown
        assert eclipse.bucket_breakdown["INFRASTRUCTURE"]["critical"] == 11

    def test_uses_latest_week_when_multiple(self):
        history = {
            "weeks": [
                {
                    "week_date": "2026-02-12",
                    "metrics": {
                        "collected_at": "2026-02-12T10:00:00",
                        "product_breakdown": {
                            "OldProduct": {
                                "critical": 99,
                                "high": 0,
                                "high_data_complete": True,
                                "buckets": {},
                                "top_cves": [],
                            }
                        },
                    },
                },
                {
                    "week_date": "2026-02-19",
                    "metrics": {
                        "collected_at": "2026-02-19T10:00:00",
                        "product_breakdown": {
                            "NewProduct": {
                                "critical": 1,
                                "high": 2,
                                "high_data_complete": True,
                                "buckets": {},
                                "top_cves": [],
                            }
                        },
                    },
                },
            ]
        }
        json_str = json.dumps(history)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result = _load_data()
        names = {m.product for m in result}
        assert "NewProduct" in names
        assert "OldProduct" not in names

    def test_returns_exploitable_metrics_instances(self, sample_history_json):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result = _load_data()
        assert all(isinstance(m, ExploitableMetrics) for m in result)


class TestLoadLatestFindings:
    """Test _load_latest_findings() — Stage 1 helper."""

    def test_returns_empty_when_no_file(self):
        with patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_path:
            mock_path.exists.return_value = False
            result = _load_latest_findings()
        assert result == {}

    def test_returns_products_dict(self):
        snapshot = {
            "collected_at": "2026-02-19T10:00:00",
            "products": {
                "Eclipse": [
                    {
                        "id": "f1",
                        "title": "Test",
                        "severity": "Critical",
                        "source": "Tenable VM",
                        "status": "OPEN",
                        "age_days": 100,
                        "cve": "CVE-2021-34527",
                        "bucket": "INFRASTRUCTURE",
                    }
                ]
            },
        }
        with patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json.dumps(snapshot)
            result = _load_latest_findings()
        assert "Eclipse" in result
        assert len(result["Eclipse"]) == 1
        assert result["Eclipse"][0]["id"] == "f1"


# ---------------------------------------------------------------------------
# Stage 2: Calculate Summary Tests
# ---------------------------------------------------------------------------


class TestCalculateSummary:
    """Test _calculate_summary() — Stage 2."""

    def test_total_exploitable(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        assert summary["total_exploitable"] == 18  # 11+4 + 0+3 + 0+0

    def test_total_critical(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        assert summary["total_critical"] == 11

    def test_total_high(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        assert summary["total_high"] == 7  # 4 + 3 + 0

    def test_products_with_exploitable(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        assert summary["products_with_exploitable"] == 2  # Eclipse + Portal
        assert summary["product_count"] == 3

    def test_status_action_when_critical(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        assert summary["status"] == "action"
        assert summary["status_text"] == "Action Needed"

    def test_status_caution_when_only_high(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="P",
                product="P",
                critical=0,
                high=5,
            )
        ]
        summary = _calculate_summary(metrics)
        assert summary["status"] == "caution"
        assert summary["status_text"] == "Caution"

    def test_status_good_when_all_zero(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="P",
                product="P",
                critical=0,
                high=0,
            )
        ]
        summary = _calculate_summary(metrics)
        assert summary["status"] == "good"
        assert summary["status_text"] == "Good"

    def test_empty_metrics_returns_zero_totals(self):
        summary = _calculate_summary([])
        assert summary["total_exploitable"] == 0
        assert summary["total_critical"] == 0
        assert summary["total_high"] == 0
        assert summary["products_with_exploitable"] == 0
        assert summary["product_count"] == 0

    def test_high_data_complete_false_when_any_incomplete(self, sample_metrics):
        # Eclipse has high_data_complete=False
        summary = _calculate_summary(sample_metrics)
        assert summary["high_data_complete"] is False

    def test_high_data_complete_true_when_all_complete(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="P",
                product="P",
                critical=5,
                high=2,
                high_data_complete=True,
            )
        ]
        summary = _calculate_summary(metrics)
        assert summary["high_data_complete"] is True

    def test_dominant_bucket_infrastructure(self, sample_metrics):
        # Eclipse: INFRASTRUCTURE 11+4=15, Portal: CODE 3
        summary = _calculate_summary(sample_metrics)
        assert summary["dominant_bucket"] == "INFRASTRUCTURE"

    def test_dominant_bucket_dash_when_no_data(self):
        summary = _calculate_summary([])
        assert summary["dominant_bucket"] == "—"

    def test_dominant_bucket_code_when_most(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="P",
                product="P",
                critical=0,
                high=0,
                bucket_breakdown={"CODE": {"critical": 0, "high": 20}},
            )
        ]
        summary = _calculate_summary(metrics)
        assert summary["dominant_bucket"] == "CODE"


# ---------------------------------------------------------------------------
# Stage 3: Generate Bucket Expanded Content Tests
# ---------------------------------------------------------------------------


class TestGenerateBucketExpandedContent:
    """Test _generate_bucket_expanded_content() — pre-rendered bucket hierarchy."""

    def test_returns_html_string(self, sample_findings):
        bd = {"INFRASTRUCTURE": {"critical": 1, "high": 1}}
        html = _generate_bucket_expanded_content(sample_findings, bd)
        assert isinstance(html, str)
        assert len(html) > 0

    def test_contains_bucket_name(self, sample_findings):
        bd = {"INFRASTRUCTURE": {"critical": 1, "high": 1}}
        html = _generate_bucket_expanded_content(sample_findings, bd)
        assert "INFRASTRUCTURE" in html

    def test_shows_vuln_table_with_findings(self, sample_findings):
        bd = {"INFRASTRUCTURE": {"critical": 1, "high": 1}}
        html = _generate_bucket_expanded_content(sample_findings, bd)
        assert "vuln-table" in html
        assert "PrintNightmare" in html
        assert "Log4Shell" in html

    def test_top_50_truncation_note_when_over_limit(self):
        findings = [
            {
                "id": str(i),
                "title": f"Vuln {i}",
                "severity": "High",
                "source": "Tenable VM",
                "status": "OPEN",
                "age_days": i,
                "cve": "",
                "bucket": "INFRASTRUCTURE",
            }
            for i in range(60)
        ]
        bd = {"INFRASTRUCTURE": {"critical": 0, "high": 60}}
        html = _generate_bucket_expanded_content(findings, bd)
        assert "50 of 60" in html

    def test_no_truncation_note_when_under_50(self, sample_findings):
        bd = {"INFRASTRUCTURE": {"critical": 1, "high": 1}}
        html = _generate_bucket_expanded_content(sample_findings, bd)
        # Should not contain truncation note for 2 findings
        assert "Top 50 of" not in html

    def test_xss_prevention_in_title(self):
        findings = [
            {
                "id": "1",
                "title": "<script>alert(1)</script>",
                "severity": "High",
                "source": "Test",
                "status": "OPEN",
                "age_days": 1,
                "cve": "",
                "bucket": "CODE",
            }
        ]
        bd = {"CODE": {"critical": 0, "high": 1}}
        html = _generate_bucket_expanded_content(findings, bd)
        assert "<script>" not in html
        assert "&lt;script&gt;" in html

    def test_xss_prevention_in_source(self):
        findings = [
            {
                "id": "1",
                "title": "Normal Title",
                "severity": "High",
                "source": '<img src=x onerror="alert(1)">',
                "status": "OPEN",
                "age_days": 1,
                "cve": "",
                "bucket": "CODE",
            }
        ]
        bd = {"CODE": {"critical": 0, "high": 1}}
        html = _generate_bucket_expanded_content(findings, bd)
        assert "<img" not in html
        assert "&lt;img" in html

    def test_empty_bucket_breakdown_returns_no_findings(self):
        html = _generate_bucket_expanded_content([], {})
        assert "no-findings" in html or "No exploitable" in html

    def test_inactive_bucket_not_in_breakdown_excluded(self, sample_findings):
        # INFRASTRUCTURE findings but only CODE in breakdown → INFRA excluded
        bd = {"CODE": {"critical": 0, "high": 1}}
        html = _generate_bucket_expanded_content(sample_findings, bd)
        assert "INFRASTRUCTURE" not in html

    def test_bucket_with_no_latest_shows_placeholder(self):
        # bucket_breakdown has INFRASTRUCTURE but no findings in latest
        bd = {"INFRASTRUCTURE": {"critical": 2, "high": 5}}
        html = _generate_bucket_expanded_content([], bd)
        assert "INFRASTRUCTURE" in html
        # Should show placeholder message
        assert "collector" in html.lower() or "unavailable" in html.lower() or "detail" in html.lower()

    def test_filter_buttons_present(self, sample_findings):
        bd = {"INFRASTRUCTURE": {"critical": 1, "high": 1}}
        html = _generate_bucket_expanded_content(sample_findings, bd)
        assert "filterBucketSeverity" in html
        assert "filterBucketVulns" in html

    def test_sort_indicators_in_thead(self, sample_findings):
        bd = {"INFRASTRUCTURE": {"critical": 1, "high": 1}}
        html = _generate_bucket_expanded_content(sample_findings, bd)
        assert "sortBucketTable" in html
        assert "sort-indicator" in html

    def test_critical_sorted_before_high(self):
        findings = [
            {
                "id": "h1",
                "title": "High Vuln",
                "severity": "High",
                "source": "S",
                "status": "OPEN",
                "age_days": 500,
                "cve": "",
                "bucket": "INFRASTRUCTURE",
            },
            {
                "id": "c1",
                "title": "Critical Vuln",
                "severity": "Critical",
                "source": "S",
                "status": "OPEN",
                "age_days": 1,
                "cve": "",
                "bucket": "INFRASTRUCTURE",
            },
        ]
        bd = {"INFRASTRUCTURE": {"critical": 1, "high": 1}}
        html = _generate_bucket_expanded_content(findings, bd)
        # Critical should appear before High in the HTML
        assert html.index("Critical Vuln") < html.index("High Vuln")


# ---------------------------------------------------------------------------
# Stage 3: Build Product Rows Tests
# ---------------------------------------------------------------------------


class TestBuildProductRows:
    """Test _build_product_rows() — Stage 3 helper."""

    def test_sorted_critical_first(self, sample_metrics):
        rows = _build_product_rows(sample_metrics)
        assert rows[0]["name"] == "Eclipse"  # 11 critical

    def test_sorted_by_high_when_no_critical(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="Alpha",
                product="Alpha",
                critical=0,
                high=1,
            ),
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="Beta",
                product="Beta",
                critical=0,
                high=10,
            ),
        ]
        rows = _build_product_rows(metrics)
        assert rows[0]["name"] == "Beta"

    def test_sorted_by_name_when_equal(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="Zebra",
                product="Zebra",
                critical=0,
                high=0,
            ),
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="Apple",
                product="Apple",
                critical=0,
                high=0,
            ),
        ]
        rows = _build_product_rows(metrics)
        assert rows[0]["name"] == "Apple"

    def test_row_has_required_keys(self, sample_metrics):
        rows = _build_product_rows(sample_metrics)
        required = {
            "name",
            "total",
            "critical",
            "high",
            "high_data_complete",
            "status",
            "status_class",
            "expanded_html",
        }
        for row in rows:
            assert required.issubset(row.keys()), f"Missing keys in row: {row}"

    def test_row_does_not_have_primary_bucket(self, sample_metrics):
        rows = _build_product_rows(sample_metrics)
        for row in rows:
            assert "primary_bucket" not in row

    def test_row_does_not_have_bucket_rows(self, sample_metrics):
        rows = _build_product_rows(sample_metrics)
        for row in rows:
            assert "bucket_rows" not in row

    def test_row_does_not_have_top_cves(self, sample_metrics):
        rows = _build_product_rows(sample_metrics)
        for row in rows:
            assert "top_cves" not in row

    def test_expanded_html_in_product_rows(self, sample_metrics, sample_findings):
        latest = {"Eclipse": sample_findings}
        rows = _build_product_rows(sample_metrics, latest)
        eclipse = next(r for r in rows if r["name"] == "Eclipse")
        assert "expanded_html" in eclipse
        assert isinstance(eclipse["expanded_html"], str)

    def test_expanded_html_contains_bucket_for_product_with_findings(self, sample_metrics, sample_findings):
        latest = {"Eclipse": sample_findings}
        rows = _build_product_rows(sample_metrics, latest)
        eclipse = next(r for r in rows if r["name"] == "Eclipse")
        assert "INFRASTRUCTURE" in eclipse["expanded_html"]

    def test_expanded_html_empty_when_no_latest(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        eclipse = next(r for r in rows if r["name"] == "Eclipse")
        # expanded_html should still be a string (placeholder or bucket with no detail)
        assert isinstance(eclipse["expanded_html"], str)

    def test_high_data_complete_propagated(self, sample_metrics):
        rows = _build_product_rows(sample_metrics)
        eclipse = next(r for r in rows if r["name"] == "Eclipse")
        assert eclipse["high_data_complete"] is False
        portal = next(r for r in rows if r["name"] == "Portal")
        assert portal["high_data_complete"] is True

    def test_correct_total_in_row(self, sample_metrics):
        rows = _build_product_rows(sample_metrics)
        eclipse = next(r for r in rows if r["name"] == "Eclipse")
        assert eclipse["total"] == 15  # 11 + 4


# ---------------------------------------------------------------------------
# Stage 3: Build Summary Cards Tests
# ---------------------------------------------------------------------------


class TestBuildSummaryCards:
    """Test _build_summary_cards() — Stage 3 helper."""

    def test_returns_four_cards(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        assert len(cards) == 4

    def test_cards_are_strings(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        assert all(isinstance(c, str) for c in cards)

    def test_cards_are_non_empty(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        assert all(len(c) > 0 for c in cards)

    def test_total_value_shown(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        combined = "".join(cards)
        # Total exploitable = 18, but with partial high → shown with +
        assert "18+" in combined or "18" in combined

    def test_partial_indicator_when_incomplete(self, sample_metrics):
        """When high data incomplete, + suffix appears."""
        summary = _calculate_summary(sample_metrics)
        # Eclipse has high_data_complete=False → incomplete
        assert summary["high_data_complete"] is False
        cards = _build_summary_cards(summary)
        combined = "".join(cards)
        assert "+" in combined


# ---------------------------------------------------------------------------
# Stage 3: Build Context Tests
# ---------------------------------------------------------------------------


class TestBuildContext:
    """Test _build_context() — Stage 3."""

    def test_framework_css_present(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        with patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest:
            mock_latest.exists.return_value = False
            context = _build_context(sample_metrics, summary)
        assert "framework_css" in context
        assert len(context["framework_css"]) > 0

    def test_framework_js_present(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        with patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest:
            mock_latest.exists.return_value = False
            context = _build_context(sample_metrics, summary)
        assert "framework_js" in context
        assert len(context["framework_js"]) > 0

    def test_summary_cards_count(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        with patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest:
            mock_latest.exists.return_value = False
            context = _build_context(sample_metrics, summary)
        assert len(context["summary_cards"]) == 4

    def test_products_count(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        with patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest:
            mock_latest.exists.return_value = False
            context = _build_context(sample_metrics, summary)
        assert len(context["products"]) == 3

    def test_show_incomplete_warning_true_when_partial(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        with patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest:
            mock_latest.exists.return_value = False
            context = _build_context(sample_metrics, summary)
        assert context["show_incomplete_warning"] is True

    def test_show_incomplete_warning_false_when_complete(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="P",
                product="P",
                critical=0,
                high=2,
                high_data_complete=True,
            )
        ]
        summary = _calculate_summary(metrics)
        with patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest:
            mock_latest.exists.return_value = False
            context = _build_context(metrics, summary)
        assert context["show_incomplete_warning"] is False

    def test_generation_date_present(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        with patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest:
            mock_latest.exists.return_value = False
            context = _build_context(sample_metrics, summary)
        assert "generation_date" in context
        assert "UTC" in context["generation_date"]

    def test_empty_metrics_no_error(self):
        summary = _calculate_summary([])
        with patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest:
            mock_latest.exists.return_value = False
            context = _build_context([], summary)
        assert "framework_css" in context
        assert context["products"] == []


# ---------------------------------------------------------------------------
# Stage 4: Generate Dashboard (end-to-end) Tests
# ---------------------------------------------------------------------------


class TestGenerateExploitableDashboard:
    """Test generate_exploitable_dashboard() — end-to-end."""

    def test_returns_html_string(self, sample_history_json, tmp_path):
        json_str = json.dumps(sample_history_json)
        with (
            patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path,
            patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest,
        ):
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            mock_latest.exists.return_value = False
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert isinstance(html, str)
        assert len(html) > 100

    def test_html_contains_product_names(self, sample_history_json, tmp_path):
        json_str = json.dumps(sample_history_json)
        with (
            patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path,
            patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest,
        ):
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            mock_latest.exists.return_value = False
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert "Eclipse" in html
        assert "Portal" in html

    def test_html_written_to_output_dir(self, sample_history_json, tmp_path):
        json_str = json.dumps(sample_history_json)
        with (
            patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path,
            patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest,
        ):
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            mock_latest.exists.return_value = False
            generate_exploitable_dashboard(output_dir=tmp_path)
        output_file = tmp_path / "exploitable_dashboard.html"
        assert output_file.exists()
        assert output_file.stat().st_size > 0

    def test_empty_history_generates_without_error(self, tmp_path):
        with (
            patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path,
            patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest,
        ):
            mock_path.exists.return_value = False
            mock_latest.exists.return_value = False
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert isinstance(html, str)

    def test_html_contains_dashboard_title(self, sample_history_json, tmp_path):
        json_str = json.dumps(sample_history_json)
        with (
            patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path,
            patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest,
        ):
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            mock_latest.exists.return_value = False
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert "Exploitable" in html

    def test_output_file_has_correct_name(self, sample_history_json, tmp_path):
        json_str = json.dumps(sample_history_json)
        with (
            patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path,
            patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest,
        ):
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            mock_latest.exists.return_value = False
            generate_exploitable_dashboard(output_dir=tmp_path)
        assert (tmp_path / "exploitable_dashboard.html").exists()

    def test_html_no_primary_bucket_column(self, sample_history_json, tmp_path):
        """Template should have 5 cols — no Primary Bucket column."""
        json_str = json.dumps(sample_history_json)
        with (
            patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path,
            patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest,
        ):
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            mock_latest.exists.return_value = False
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert "Primary Bucket" not in html

    def test_html_no_known_cves_section(self, sample_history_json, tmp_path):
        """Known CVEs section should be removed."""
        json_str = json.dumps(sample_history_json)
        with (
            patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path,
            patch("execution.dashboards.exploitable_dashboard.LATEST_PATH") as mock_latest,
        ):
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            mock_latest.exists.return_value = False
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert "Known CVEs" not in html
