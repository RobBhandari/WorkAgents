"""
Tests for Exploitable Vulnerabilities Dashboard Generator

Tests cover:
- Domain model: ExploitableMetrics properties and from_json()
- Stage 1: Data loading from exploitable_history.json (mocked)
- Stage 2: Summary calculation (totals, status determination, medium counts)
- Stage 3: Product row generation, summary cards, context building
- Stage 4: End-to-end dashboard generation with mocked file I/O
- Edge cases: empty data, all-zero counts, medium-only status, backward compat, XSS prevention
"""

import json
from datetime import datetime
from pathlib import Path
from unittest.mock import patch

import pytest

from execution.dashboards.exploitable_dashboard import (
    _build_context,
    _build_product_rows,
    _build_product_trends,
    _build_summary_cards,
    _calculate_summary,
    _load_data,
    _load_id_map,
    generate_exploitable_dashboard,
)
from execution.domain.exploitable import ExploitableMetrics

# ---------------------------------------------------------------------------
# Fixtures
# ---------------------------------------------------------------------------


@pytest.fixture
def sample_timestamp() -> datetime:
    return datetime(2026, 2, 19, 10, 0, 0)


@pytest.fixture
def sample_metrics(sample_timestamp) -> list[ExploitableMetrics]:
    """Three products with varying exploitable counts including medium."""
    return [
        ExploitableMetrics(
            timestamp=sample_timestamp,
            project="Eclipse",
            product="Eclipse",
            critical=11,
            high=4,
            medium=5,
        ),
        ExploitableMetrics(
            timestamp=sample_timestamp,
            project="Portal",
            product="Portal",
            critical=0,
            high=3,
            medium=2,
        ),
        ExploitableMetrics(
            timestamp=sample_timestamp,
            project="CleanProduct",
            product="CleanProduct",
            critical=0,
            high=0,
            medium=0,
        ),
    ]


@pytest.fixture
def sample_trends() -> dict[str, list[int]]:
    return {"Product A": [10, 15, 12], "Product B": [5, 3, 8]}


@pytest.fixture
def sample_history_json() -> dict:
    """History JSON matching the collector output format with medium field."""
    return {
        "weeks": [
            {
                "week_date": "2026-02-19",
                "week_number": 8,
                "metrics": {
                    "current_total": 25,
                    "severity_breakdown": {"critical": 11, "high": 7, "medium": 7, "total": 25},
                    "collected_at": "2026-02-19T10:00:00",
                    "product_breakdown": {
                        "Eclipse": {
                            "critical": 11,
                            "high": 4,
                            "medium": 5,
                            "total": 20,
                        },
                        "Portal": {
                            "critical": 0,
                            "high": 3,
                            "medium": 2,
                            "total": 5,
                        },
                    },
                },
            }
        ]
    }


# ---------------------------------------------------------------------------
# Domain Model Tests
# ---------------------------------------------------------------------------


class TestExploitableMetrics:
    """Test ExploitableMetrics domain model properties and factory method."""

    def test_total_is_critical_plus_high_plus_medium(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=5, high=3, medium=2)
        assert m.total == 10

    def test_total_zero(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=0, high=0, medium=0)
        assert m.total == 0

    def test_total_medium_default_zero(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=5, high=3)
        assert m.medium == 0
        assert m.total == 8

    def test_status_action_needed_when_critical(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=1, high=0)
        assert m.status == "Action Needed"
        assert m.status_class == "action"

    def test_status_caution_when_only_high(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=0, high=5)
        assert m.status == "Caution"
        assert m.status_class == "caution"

    def test_status_caution_when_only_medium(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=0, high=0, medium=5)
        assert m.status == "Caution"
        assert m.status_class == "caution"

    def test_status_good_when_zero(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=0, high=0, medium=0)
        assert m.status == "Good"
        assert m.status_class == "good"

    def test_status_action_overrides_high_and_medium(self, sample_timestamp):
        """Critical trumps High and Medium — status is Action Needed even if both > 0."""
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=3, high=10, medium=7)
        assert m.status == "Action Needed"
        assert m.status_class == "action"

    def test_primary_bucket_returns_highest_total(self, sample_timestamp):
        m = ExploitableMetrics(
            timestamp=sample_timestamp,
            project="P",
            product="P",
            critical=0,
            high=0,
            bucket_breakdown={
                "CODE": {"critical": 0, "high": 2},
                "INFRASTRUCTURE": {"critical": 5, "high": 1},
            },
        )
        assert m.primary_bucket == "INFRASTRUCTURE"

    def test_primary_bucket_code_when_most(self, sample_timestamp):
        m = ExploitableMetrics(
            timestamp=sample_timestamp,
            project="P",
            product="P",
            critical=0,
            high=0,
            bucket_breakdown={
                "CODE": {"critical": 0, "high": 10},
                "INFRASTRUCTURE": {"critical": 1, "high": 0},
            },
        )
        assert m.primary_bucket == "CODE"

    def test_primary_bucket_other_when_empty(self, sample_timestamp):
        m = ExploitableMetrics(
            timestamp=sample_timestamp,
            project="P",
            product="P",
            critical=0,
            high=0,
            bucket_breakdown={},
        )
        assert m.primary_bucket == "Other"

    def test_from_json_populates_all_fields(self, sample_timestamp):
        data = {
            "critical": 11,
            "high": 4,
            "medium": 3,
            "high_data_complete": True,
            "buckets": {"INFRASTRUCTURE": {"critical": 11, "high": 4}},
            "top_cves": ["CVE-2025-59287"],
        }
        m = ExploitableMetrics.from_json("Eclipse", data, sample_timestamp)
        assert m.product == "Eclipse"
        assert m.critical == 11
        assert m.high == 4
        assert m.medium == 3
        assert m.high_data_complete is True
        assert m.bucket_breakdown == {"INFRASTRUCTURE": {"critical": 11, "high": 4}}
        assert m.top_cves == ["CVE-2025-59287"]
        assert m.timestamp == sample_timestamp

    def test_from_json_defaults_for_missing_fields(self, sample_timestamp):
        data = {"critical": 2, "high": 0}
        m = ExploitableMetrics.from_json("Minimal", data, sample_timestamp)
        assert m.critical == 2
        assert m.high == 0
        assert m.medium == 0
        assert m.high_data_complete is True
        assert m.bucket_breakdown == {}
        assert m.top_cves == []

    def test_from_json_sets_project_and_product(self, sample_timestamp):
        m = ExploitableMetrics.from_json("TestProd", {}, sample_timestamp)
        assert m.project == "TestProd"
        assert m.product == "TestProd"

    def test_from_json_reads_medium_field(self, sample_timestamp):
        data = {"critical": 1, "high": 2, "medium": 7}
        m = ExploitableMetrics.from_json("P", data, sample_timestamp)
        assert m.medium == 7

    def test_medium_included_in_total(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=1, high=2, medium=3)
        assert m.total == 6

    def test_medium_status_is_caution(self, sample_timestamp):
        m = ExploitableMetrics(timestamp=sample_timestamp, project="P", product="P", critical=0, high=0, medium=5)
        assert m.status == "Caution"
        assert m.status_class == "caution"

    def test_backward_compat_no_medium_in_old_history(self, sample_timestamp):
        """Old history entries without 'medium' should default to 0."""
        data = {"critical": 5, "high": 10}  # no "medium" key
        m = ExploitableMetrics.from_json("OldProduct", data, sample_timestamp)
        assert m.medium == 0
        assert m.total == 15


# ---------------------------------------------------------------------------
# Stage 1: Load Data Tests
# ---------------------------------------------------------------------------


class TestLoadData:
    """Test _load_data() — Stage 1."""

    def test_returns_empty_when_no_history_file(self):
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = False
            result = _load_data()
        assert result == ([], {})

    def test_returns_empty_when_no_weeks(self):
        empty = json.dumps({"weeks": []})
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = empty
            result = _load_data()
        assert result == ([], {})

    def test_loads_products_from_latest_week(self, sample_history_json):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result, _ = _load_data()
        assert len(result) == 2
        names = {m.product for m in result}
        assert "Eclipse" in names
        assert "Portal" in names

    def test_loads_correct_counts(self, sample_history_json):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result, _ = _load_data()
        eclipse = next(m for m in result if m.product == "Eclipse")
        assert eclipse.critical == 11
        assert eclipse.high == 4
        assert eclipse.medium == 5

    def test_loads_medium_counts(self, sample_history_json):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result, _ = _load_data()
        portal = next(m for m in result if m.product == "Portal")
        assert portal.medium == 2

    def test_uses_latest_week_when_multiple(self):
        history = {
            "weeks": [
                {
                    "week_date": "2026-02-12",
                    "metrics": {
                        "collected_at": "2026-02-12T10:00:00",
                        "product_breakdown": {
                            "OldProduct": {
                                "critical": 99,
                                "high": 0,
                                "medium": 0,
                                "total": 99,
                            }
                        },
                    },
                },
                {
                    "week_date": "2026-02-19",
                    "metrics": {
                        "collected_at": "2026-02-19T10:00:00",
                        "product_breakdown": {
                            "NewProduct": {
                                "critical": 1,
                                "high": 2,
                                "medium": 3,
                                "total": 6,
                            }
                        },
                    },
                },
            ]
        }
        json_str = json.dumps(history)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result, _ = _load_data()
        names = {m.product for m in result}
        assert "NewProduct" in names
        assert "OldProduct" not in names

    def test_returns_exploitable_metrics_instances(self, sample_history_json):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result, _ = _load_data()
        assert all(isinstance(m, ExploitableMetrics) for m in result)

    def test_translates_product_ids_to_names(self):
        """Numeric product IDs in history are translated to names via the ID map."""
        history = {
            "weeks": [
                {
                    "week_date": "2026-02-19",
                    "metrics": {
                        "collected_at": "2026-02-19T10:00:00",
                        "product_breakdown": {
                            "45454": {"critical": 11, "high": 4, "medium": 5, "total": 20},
                        },
                    },
                }
            ]
        }
        id_map = {"Eclipse": "45454"}
        json_str = json.dumps(history)
        with (
            patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path,
            patch("execution.dashboards.exploitable_dashboard._load_id_map", return_value=id_map),
        ):
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result, trends = _load_data()
        assert len(result) == 1
        assert result[0].product == "Eclipse"
        assert "Eclipse" in trends
        assert "45454" not in trends

    def test_falls_back_to_id_when_map_missing(self):
        """When ID map file is absent, product IDs are shown as-is (graceful degradation)."""
        history = {
            "weeks": [
                {
                    "week_date": "2026-02-19",
                    "metrics": {
                        "collected_at": "2026-02-19T10:00:00",
                        "product_breakdown": {
                            "99999": {"critical": 1, "high": 0, "medium": 0, "total": 1},
                        },
                    },
                }
            ]
        }
        json_str = json.dumps(history)
        with (
            patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path,
            patch(
                "execution.dashboards.exploitable_dashboard._load_id_map",
                side_effect=FileNotFoundError,
            ),
        ):
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result, trends = _load_data()
        assert len(result) == 1
        assert result[0].product == "99999"
        assert "99999" in trends

    def test_old_history_without_medium_defaults_to_zero(self):
        """Backward compatibility: old history without medium key should produce medium=0."""
        history = {
            "weeks": [
                {
                    "week_date": "2026-01-01",
                    "metrics": {
                        "collected_at": "2026-01-01T10:00:00",
                        "product_breakdown": {
                            "LegacyProduct": {
                                "critical": 3,
                                "high": 2,
                                # no "medium" key
                                "total": 5,
                            }
                        },
                    },
                }
            ]
        }
        json_str = json.dumps(history)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            result, _ = _load_data()
        assert len(result) == 1
        assert result[0].medium == 0
        assert result[0].total == 5


# ---------------------------------------------------------------------------
# Stage 2: Calculate Summary Tests
# ---------------------------------------------------------------------------


class TestCalculateSummary:
    """Test _calculate_summary() — Stage 2."""

    def test_total_exploitable_includes_medium(self, sample_metrics):
        # Eclipse: 11+4+5=20, Portal: 0+3+2=5, CleanProduct: 0
        summary = _calculate_summary(sample_metrics)
        assert summary["total_exploitable"] == 25

    def test_total_critical(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        assert summary["total_critical"] == 11

    def test_total_high(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        assert summary["total_high"] == 7  # 4 + 3 + 0

    def test_total_medium(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        assert summary["total_medium"] == 7  # 5 + 2 + 0

    def test_products_with_exploitable(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        assert summary["products_with_exploitable"] == 2  # Eclipse + Portal
        assert summary["product_count"] == 3

    def test_status_action_when_critical(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        assert summary["status"] == "action"
        assert summary["status_text"] == "Action Needed"

    def test_status_caution_when_only_high(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="P",
                product="P",
                critical=0,
                high=5,
                medium=0,
            )
        ]
        summary = _calculate_summary(metrics)
        assert summary["status"] == "caution"
        assert summary["status_text"] == "Caution"

    def test_status_caution_when_only_medium(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="P",
                product="P",
                critical=0,
                high=0,
                medium=3,
            )
        ]
        summary = _calculate_summary(metrics)
        assert summary["status"] == "caution"
        assert summary["status_text"] == "Caution"

    def test_status_good_when_all_zero(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="P",
                product="P",
                critical=0,
                high=0,
                medium=0,
            )
        ]
        summary = _calculate_summary(metrics)
        assert summary["status"] == "good"
        assert summary["status_text"] == "Good"

    def test_empty_metrics_returns_zero_totals(self):
        summary = _calculate_summary([])
        assert summary["total_exploitable"] == 0
        assert summary["total_critical"] == 0
        assert summary["total_high"] == 0
        assert summary["total_medium"] == 0
        assert summary["products_with_exploitable"] == 0
        assert summary["product_count"] == 0

    def test_total_medium_key_present(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        assert "total_medium" in summary

    def test_total_exploitable_zero_when_all_zero(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="P",
                product="P",
                critical=0,
                high=0,
                medium=0,
            )
        ]
        summary = _calculate_summary(metrics)
        assert summary["total_exploitable"] == 0

    def test_total_exploitable_medium_only(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="P",
                product="P",
                critical=0,
                high=0,
                medium=4,
            )
        ]
        summary = _calculate_summary(metrics)
        assert summary["total_exploitable"] == 4
        assert summary["total_medium"] == 4


# ---------------------------------------------------------------------------
# Stage 3: Build Product Rows Tests
# ---------------------------------------------------------------------------


class TestBuildProductRows:
    """Test _build_product_rows() — Stage 3 helper."""

    def test_sorted_critical_first(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        assert rows[0]["name"] == "Eclipse"  # 11 critical

    def test_sorted_by_high_when_no_critical(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="Alpha",
                product="Alpha",
                critical=0,
                high=1,
                medium=0,
            ),
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="Beta",
                product="Beta",
                critical=0,
                high=10,
                medium=0,
            ),
        ]
        rows = _build_product_rows(metrics, {})
        assert rows[0]["name"] == "Beta"

    def test_sorted_by_medium_when_no_critical_or_high(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="Alpha",
                product="Alpha",
                critical=0,
                high=0,
                medium=2,
            ),
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="Beta",
                product="Beta",
                critical=0,
                high=0,
                medium=8,
            ),
        ]
        rows = _build_product_rows(metrics, {})
        assert rows[0]["name"] == "Beta"

    def test_sorted_by_name_when_equal(self, sample_timestamp):
        metrics = [
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="Zebra",
                product="Zebra",
                critical=0,
                high=0,
                medium=0,
            ),
            ExploitableMetrics(
                timestamp=sample_timestamp,
                project="Apple",
                product="Apple",
                critical=0,
                high=0,
                medium=0,
            ),
        ]
        rows = _build_product_rows(metrics, {})
        assert rows[0]["name"] == "Apple"

    def test_row_has_required_keys(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        required = {
            "name",
            "total",
            "critical",
            "high",
            "medium",
            "status",
            "status_class",
        }
        for row in rows:
            assert required.issubset(row.keys()), f"Missing keys in row: {row}"

    def test_row_has_medium_key(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        for row in rows:
            assert "medium" in row

    def test_row_does_not_have_expanded_html(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        for row in rows:
            assert "expanded_html" not in row

    def test_row_does_not_have_primary_bucket(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        for row in rows:
            assert "primary_bucket" not in row

    def test_row_does_not_have_bucket_rows(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        for row in rows:
            assert "bucket_rows" not in row

    def test_row_does_not_have_top_cves(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        for row in rows:
            assert "top_cves" not in row

    def test_correct_total_in_row_includes_medium(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        eclipse = next(r for r in rows if r["name"] == "Eclipse")
        assert eclipse["total"] == 20  # 11 + 4 + 5

    def test_medium_value_in_row(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        eclipse = next(r for r in rows if r["name"] == "Eclipse")
        assert eclipse["medium"] == 5
        portal = next(r for r in rows if r["name"] == "Portal")
        assert portal["medium"] == 2

    def test_clean_product_has_zero_medium(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        clean = next(r for r in rows if r["name"] == "CleanProduct")
        assert clean["medium"] == 0

    def test_product_row_has_trend_sparkline(self, sample_trends: dict) -> None:
        """Product rows include trend_sparkline key from trend data."""
        m = ExploitableMetrics(
            timestamp=datetime(2026, 2, 20),
            project="Product A",
            product="Product A",
            critical=1,
            high=2,
            medium=0,
        )
        rows = _build_product_rows([m], sample_trends)
        assert "trend_sparkline" in rows[0]
        assert rows[0]["trend_sparkline"] != ""  # 3 data points → non-empty SVG

    def test_trend_sparkline_empty_for_single_datapoint(self) -> None:
        """Sparkline is empty string when only one data point exists."""
        m = ExploitableMetrics(
            timestamp=datetime(2026, 2, 20),
            project="Solo",
            product="Solo",
            critical=0,
            high=1,
            medium=0,
        )
        rows = _build_product_rows([m], {"Solo": [5]})
        assert rows[0]["trend_sparkline"] == ""

    def test_build_product_trends_builds_per_product_list(self) -> None:
        """_build_product_trends returns per-product total lists across weeks."""
        weeks = [
            {"metrics": {"product_breakdown": {"A": {"total": 10}, "B": {"total": 5}}}},
            {"metrics": {"product_breakdown": {"A": {"total": 15}}}},
            {"metrics": {"product_breakdown": {"A": {"total": 12}, "B": {"total": 8}}}},
        ]
        trends = _build_product_trends(weeks)
        assert trends["A"] == [10, 15, 12]
        assert trends["B"] == [5, 0, 8]  # 0 for week where B was absent


# ---------------------------------------------------------------------------
# Stage 3: Build Summary Cards Tests
# ---------------------------------------------------------------------------


class TestBuildSummaryCards:
    """Test _build_summary_cards() — Stage 3 helper."""

    def test_returns_five_cards(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        assert len(cards) == 5

    def test_cards_are_strings(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        assert all(isinstance(c, str) for c in cards)

    def test_cards_are_non_empty(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        assert all(len(c) > 0 for c in cards)

    def test_total_value_shown(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        combined = "".join(cards)
        assert "25" in combined

    def test_medium_card_present(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        combined = " ".join(cards)
        assert "Medium" in combined

    def test_critical_card_present(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        combined = " ".join(cards)
        assert "Critical" in combined

    def test_high_card_present(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        combined = " ".join(cards)
        assert "High" in combined

    def test_products_affected_card_present(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        combined = " ".join(cards)
        assert "Products" in combined

    def test_medium_card_in_summary_cards(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        cards = _build_summary_cards(summary)
        assert len(cards) == 5
        combined = " ".join(cards)
        assert "Medium" in combined

    def test_product_row_has_medium(self, sample_metrics):
        rows = _build_product_rows(sample_metrics, {})
        for row in rows:
            assert "medium" in row
            assert "expanded_html" not in row


# ---------------------------------------------------------------------------
# Stage 3: Build Context Tests
# ---------------------------------------------------------------------------


class TestBuildContext:
    """Test _build_context() — Stage 3."""

    def test_framework_css_present(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        context = _build_context(sample_metrics, summary, {})
        assert "framework_css" in context
        assert len(context["framework_css"]) > 0

    def test_framework_js_present(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        context = _build_context(sample_metrics, summary, {})
        assert "framework_js" in context
        assert len(context["framework_js"]) > 0

    def test_summary_cards_count_is_five(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        context = _build_context(sample_metrics, summary, {})
        assert len(context["summary_cards"]) == 5

    def test_products_count(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        context = _build_context(sample_metrics, summary, {})
        assert len(context["products"]) == 3

    def test_generation_date_present(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        context = _build_context(sample_metrics, summary, {})
        assert "generation_date" in context
        assert "UTC" in context["generation_date"]

    def test_empty_metrics_no_error(self):
        summary = _calculate_summary([])
        context = _build_context([], summary, {})
        assert "framework_css" in context
        assert context["products"] == []

    def test_context_has_summary_key(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        context = _build_context(sample_metrics, summary, {})
        assert "summary" in context
        assert context["summary"] is summary

    def test_no_show_incomplete_warning_key(self, sample_metrics):
        """show_incomplete_warning has been removed from context."""
        summary = _calculate_summary(sample_metrics)
        context = _build_context(sample_metrics, summary, {})
        assert "show_incomplete_warning" not in context

    def test_products_have_medium_key(self, sample_metrics):
        summary = _calculate_summary(sample_metrics)
        context = _build_context(sample_metrics, summary, {})
        for product in context["products"]:
            assert "medium" in product


# ---------------------------------------------------------------------------
# Stage 4: Generate Dashboard (end-to-end) Tests
# ---------------------------------------------------------------------------


class TestGenerateExploitableDashboard:
    """Test generate_exploitable_dashboard() — end-to-end."""

    def test_returns_html_string(self, sample_history_json, tmp_path):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert isinstance(html, str)
        assert len(html) > 100

    def test_html_contains_product_names(self, sample_history_json, tmp_path):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert "Eclipse" in html
        assert "Portal" in html

    def test_html_written_to_output_dir(self, sample_history_json, tmp_path):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            generate_exploitable_dashboard(output_dir=tmp_path)
        output_file = tmp_path / "exploitable_dashboard.html"
        assert output_file.exists()
        assert output_file.stat().st_size > 0

    def test_empty_history_generates_without_error(self, tmp_path):
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = False
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert isinstance(html, str)

    def test_html_contains_dashboard_title(self, sample_history_json, tmp_path):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert "Exploitable" in html

    def test_output_file_has_correct_name(self, sample_history_json, tmp_path):
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            generate_exploitable_dashboard(output_dir=tmp_path)
        assert (tmp_path / "exploitable_dashboard.html").exists()

    def test_html_no_primary_bucket_column(self, sample_history_json, tmp_path):
        """Template should not contain Primary Bucket column."""
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert "Primary Bucket" not in html

    def test_html_no_known_cves_section(self, sample_history_json, tmp_path):
        """Known CVEs section should be removed."""
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert "Known CVEs" not in html

    def test_html_contains_medium_in_output(self, sample_history_json, tmp_path):
        """Dashboard HTML should reference Medium severity."""
        json_str = json.dumps(sample_history_json)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert "Medium" in html

    def test_e2e_with_medium_only_product(self, tmp_path):
        """Product with only medium vulns should appear in dashboard without error."""
        history = {
            "weeks": [
                {
                    "week_date": "2026-02-19",
                    "metrics": {
                        "collected_at": "2026-02-19T10:00:00",
                        "product_breakdown": {
                            "MediumOnlyProduct": {
                                "critical": 0,
                                "high": 0,
                                "medium": 6,
                                "total": 6,
                            }
                        },
                    },
                }
            ]
        }
        json_str = json.dumps(history)
        with patch("execution.dashboards.exploitable_dashboard.HISTORY_PATH") as mock_path:
            mock_path.exists.return_value = True
            mock_path.read_text.return_value = json_str
            html = generate_exploitable_dashboard(output_dir=tmp_path)
        assert isinstance(html, str)
        assert "MediumOnlyProduct" in html
